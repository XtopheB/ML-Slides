%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  This Beamer template was created by Cameron Bracken.

\documentclass[xcolor=x11names,compress, aspectratio=169]{beamer}
%\documentclass[xcolor=x11names,compress, handhouts, aspectratio=169]{beamer}
%% General document
\usepackage{graphicx, subfig}
%% Beamer Layout
\useoutertheme[subsection=false,shadow]{miniframes}
\useinnertheme{default}
\usefonttheme{serif}
\usepackage{palatino}

%%%%%%% Mes Packages %%%%%%%%%%%%%%%%
%\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage{xcolor}
\usepackage{dsfont} % Pour indicatrice
\usepackage{url}
\usepackage{multirow}
%remove the icon
\setbeamertemplate{bibliography item}{}

%remove line breaks
\setbeamertemplate{bibliography entry title}{}
\setbeamertemplate{bibliography entry location}{}
\setbeamertemplate{bibliography entry note}{}

%% ------ MEs couleurs --------
\definecolor{vert}{rgb}{0.1,0.7,0.2}
\definecolor{brique}{rgb}{0.7,0.16,0.16}
\definecolor{gris}{rgb}{0.7, 0.75, 0.71}
\definecolor{twitterblue}{rgb}{0, 0.42, 0.58}
\definecolor{airforceblue}{rgb}{0.36, 0.54, 0.66}
\definecolor{siap}{RGB}{3,133, 168}


%%%%%%%%%%%%%%%%% BEAMER PACKAGE %%%%%%%

\setbeamerfont{title like}{shape=\scshape}
\setbeamerfont{frametitle}{shape=\scshape}

\setbeamercolor*{lower separation line head}{bg=DeepSkyBlue4}
\setbeamercolor*{normal text}{fg=black,bg=white}
\setbeamercolor*{alerted text}{fg=red}
\setbeamercolor*{example text}{fg=black}
\setbeamercolor*{structure}{fg=black}
\setbeamercolor*{palette tertiary}{fg=black,bg=black!10}
\setbeamercolor*{palette quaternary}{fg=black,bg=black!10}

\renewcommand{\(}{\begin{columns}}
\renewcommand{\)}{\end{columns}}
\newcommand{\<}[1]{\begin{column}{#1}}
\renewcommand{\>}{\end{column}}

% Path for the graphs
\graphicspath{{Graphics/}{../../../../Visualisation/Presentations/Graphics/}{../../Visualisation/Presentations/Graphics/}{c:/Gitmain/MLCourse/UNML/Module0/M0_files/figure-html/}  }

%remove navigation symbols
\setbeamertemplate{navigation symbols}{}


% Natbib for clean bibliography
\usepackage[comma,authoryear]{natbib}

\begin{document}

\begin{frame}
\Large{ \color{siap}{Machine Learning for Official Statistics and SDGs}}

\hspace{1cm}

\color{brique}{\huge{Statistical learning: \\ \textit{You've seen this before}}}

\hspace{2cm}
\begin{center}

\includegraphics[height=0.10\textwidth]{SIAP_logo_Big.png}

\end{center}



\end{frame}

%

%%%  ----------- Dataviz  Definition  -----------%%%

\section{Introduction}

\begin{frame} % Cover slide
\frametitle{Who is this course for?}
\pause
\begin{itemize}[<+->]
  \item This course is for (present or future) Data Scientists
  \item This course uses both statistical and computational concepts
  \item This course uses many applied examples and a very progressive approach
  \item[]
\begin{center}
\emph{Data Scientist: “Person who is better at statistics than any software engineer and better at software than any statistician.” }
\end{center}
\scriptsize{J. Wills (2012)}
\end{itemize}
\end{frame}

\begin{frame} % Cover slide
\frametitle{What Is Statistical Learning?}
\begin{center}
\emph{`` Statistical learning refers to a vast set of tools for understanding data''}
{\scriptsize Gareth James,  Daniela Witten, Trevor Hastie ,  Robert Tibshirani (2021)}
\end{center}
\begin{itemize}
 \item<+->[]
  \item<+->Involves building statistical models
  \item<+-> Goals are estimation or Prediction
 \end{itemize}
\end{frame}


\begin{frame} % Cover slide
\frametitle{What Is Statistical Learning?}
Two main learning problems:
\begin{itemize}
  \item<+->[]We observe \textbf{both} the outcome $y$ and regressors (also called features) $x$s
   \item<+-> \textbf{Supervised} learning
  \item<+->[] We \textbf{do not} observe the outcome $y$ but\textbf{ only} several $x$s
  \item<+-> \textbf{Unsupervised} learning (or \textit{cluster analysis})
 \end{itemize}
\end{frame}



\begin{frame} % Cover slide
\frametitle{Understanding data on an example}
 \begin{itemize}
  \item<+->[] \includegraphics[width = 0.7\textwidth]{M0-Scatter-1.png}
  \item<+->[]  We may be interested in the relationship between the two variables
 \end{itemize}
\end{frame}



\begin{frame} % Cover slide
\frametitle{Understanding = estimate $f(\cdot)$ }
 \begin{itemize}
  \item<+->[] \includegraphics[width = 0.7\textwidth]{M0-Scatter-lm-1.png}
  \item<+->[]  $f(\cdot)$ is the regression line
 \end{itemize}
\end{frame}


\begin{frame} % Cover slide
\frametitle{Why estimating $f(\cdot)$ ?}
 \begin{itemize}
  \item<+-> Inference
   \begin{itemize}
  \item<+->[] Understand the nature of the relationship between $X$ and $Y$
  \item<+->[] Identify  "important" variables to understand $Y$
 \end{itemize}
  \item<+-> Prediction
   \begin{itemize}
  \item<+->[] Predict $y$ for any new $x$ using $f(\cdot)$
 \end{itemize}
 \item<+-> In practice we must estimate  $f(\cdot)$ using a model:
 \item<+->[] $$ y = f(x) + \varepsilon $$
 \item<+->[] We denote by $\widehat{f(\cdot)}$ the estimate of $f(\cdot)$
 \end{itemize}
\end{frame}


\begin{frame} % Cover slide
\frametitle{How to estimate $f(\cdot)$?}
 \begin{itemize}
  \item<+-> Parametric methods
   \begin{itemize}
      \item<+->[] Specify a form for $f(\cdot)$, for example linear
      \item<+->[] $$y = \beta_0 + \beta_1 x_ + \varepsilon$$
      \item<+-> The problem is then to estimate $ \beta_0$ and $\beta_1$
      \item<+-> The goal is to find the line that \textbf{minimize} the distance to the observed points $(x_i, y_i)$
      \item<+->[] $$Min_{\; (\beta_0 , \beta_1)} \;  \; \; \sum_{i=1}^{n} \bigl(y_i - (\beta_0 + \beta_1 x_i)\bigr)^2$$
 \end{itemize}
 \item<+->[] \textbf{NB:} $\sum_{i=1}^{n} \bigl(y_i - (\beta_0 + \beta_1 x_i)\bigr)^2$ is a \textit{cost function} of the parameters $ (\beta_0,\beta_1)$
 \end{itemize}
\end{frame}



\begin{frame} % Cover slide
\frametitle{How to estimate $f(\cdot)$: In practice}
 \begin{itemize}
  \item<+->[] \includegraphics[width = 0.7\textwidth]{M0-scatter-Regline-1.png}
  \item<+->[] Usually, the regression line is found using an OLS procedure
 \end{itemize}
\end{frame}


\begin{frame} % Cover slide
\frametitle{Results ($ \widehat{f(\cdot)}$}
Results:  There is a relation, and it is decreasing.
\begin{table}
\centering
\begin{tabular}{l|rrrc}
\hline
  & Estimate & Std. Error & t value & $Pr(>|t|)$\\
\hline
(Intercept) & 1.75 & 0.04 & 41.09 & 0\\
\hline
ltexp & $-0.20^{***}$ & 0.01 & -31.84 & 0\\
\hline
\end{tabular}
\end{table}
 The  $R^2$ = 0.478

\end{frame}


\begin{frame} % Cover slide
\frametitle{What did we learn?}
 \begin{itemize}
  \item<+-> Is the line fitting the data?
   \begin{itemize}
      \item<+->[] One may always find a relation between two variables
      \item<+->[] Statistical test help asses the significance of a variable
  \end{itemize}
  \item<+-> How good is the linear adjustment: $R^2$
  \begin{itemize}
      \item<+->[] $$R^2 = \frac{TSS- RSS}{TSS}$$
      \item<+->[] with:  $TSS= \sum_{i=1}^n (y_i -\bar{y})^2 $ and $RSS= \sum_{i=1}^n (y_i - \widehat{f}(x_i))^2 $
 \end{itemize}
 \item<+-> $R^2$ is a very popular measure but can be very misleading
 \end{itemize}
\end{frame}


\section{Beware of $R^2$ }

\begin{frame} % Cover slide
\frametitle{Beware of $R^2$: Anscombe Quartet (1973)}
\pause
 \begin{itemize}
  \item<+->[] \includegraphics[width = 0.5\textwidth]{AnscombeQuartet.png}
  \item<+->[] In all these data sets the $R^2$ is 0.67
 \end{itemize}
\end{frame}


\begin{frame} % Cover slide
\frametitle{Practice of Statistical Learning}
\begin{center}
\emph{`` ...make both calculations and graphs. Both sorts of output should be studied; each will contribute to understanding.''}
\end{center}
\begin{itemize}
 \item<+->[]\scriptsize{F. J. Anscombe (1973)}
 \item<+->[] \scriptsize{See also \href{https://www.r-bloggers.com/2017/05/the-datasaurus-dozen/}{the datasaurus}}
  \item<+->Practice of Statistical learning can be challenging
  \item<+->[] Need to compute good indicators
  \item<+->[] Need to understand the indicators computed
  \item<+->[] Need to go beyond linearity
  \item<+->[] Need to see into the darkness of data clouds...
 \end{itemize}
\end{frame}


\section{Beyond linearity}
\begin{frame} % Cover slide
\frametitle{Beyond linearity}

\begin{itemize}
 \item A non-linear model may be better adapted: \textbf{linear} model
 \item[]  $$y = \beta_0 + \beta_1 x + \varepsilon$$
 \item[] \includegraphics[width = 0.6\textwidth]{M0-Scatter-lmCI-1.png}
 \item[] the fit (measured by $R^2$) is: $R^2$= 0.478
 \end{itemize}
\end{frame}


\begin{frame} % Cover slide
\frametitle{Beyond linearity}

\begin{itemize}
 \item A Polynomial model may be better adapted: \textbf{Quadratic} model
 \item[]  $$y = \beta_0 + \beta_1 x +  \beta_2 x^2+ \varepsilon$$
 \item[] \includegraphics[width = 0.6\textwidth]{M0-Scatter-poly2-1.png}
 \item[] Do we have a better fit? $R^2$= 0.484
 \end{itemize}
\end{frame}

\begin{frame} % Cover slide
\frametitle{Beyond linearity}

\begin{itemize}
 \item Polynomial may be better adapted: \textbf{Cubic} model
 \item[]  $$y = \beta_0 + \beta_1 x +  \beta_2 x^2 + \beta_3 x^3+ \varepsilon$$
 \item[] \includegraphics[width = 0.6\textwidth]{M0-Scatter-poly3-1.png}
 \item[] Do we have a better fit? $R^2$= 0.490
 \end{itemize}
\end{frame}

\begin{frame} % Cover slide
\frametitle{In practice}

\begin{itemize}[<+->]
 \item Polynomial models may be useful
 \item[]  $$y = \beta_0 + \beta_1 x +  \beta_2 x^2 + \cdots + \beta_p x^p + \varepsilon$$
 \item[] How to choose the degree $p$ ?
 \item[] Colinearity of $x^p$ and $x^q$ for $ p \neq q$? 
 \end{itemize}
\end{frame}

\section{K-NN}

\begin{frame} % Cover slide
\frametitle{Parametric vs nonparametric models}

\begin{itemize}[<+->]
     \item Linear and polynomial models are determined by parameters ($\beta_0, \beta_2, \cdots, \beta_p$)
     \item Other methods more flexible
       \item Nearest neighbors  (or k-NN)
     \begin{itemize}[<+->]
         \item[] The goal is to estimate $f(\cdot)$ not $\beta_s$!
         \item[] Similar in spirit to moving average
         \item[] $$ \widehat{f} (x_i) = \frac{1}{k} \sum_{j \in \, \{ k-nearest\, neighbours \, of \, x_i \} }  y_i$$
         \item[] $k$ is the number of neighbors of $x_i$ taken into account in estimation.
     \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{\textcolor{brique}{ K-NN in practice}}
\begin{center}
\begin{itemize}
   \only<1> {\includegraphics[width = 0.8\textwidth]{k-NN-0.png} \\ }
   \only<2> {\includegraphics[width = 0.8\textwidth]{k-NN-1.png} \\ }
   \only<3> {\includegraphics[width = 0.8\textwidth]{k-NN-2.png} \\ }
   \only<4> {\includegraphics[width = 0.8\textwidth]{k-NN-3.png} \\ }
   \only<5> {\includegraphics[width = 0.8\textwidth]{k-NN-4.png} \\ }
   \only<6> {\includegraphics[width = 0.8\textwidth]{k-NN-5.png} \\ }
   \only<7> {\includegraphics[width = 0.8\textwidth]{k-NN-6.png} \\ }
\end{itemize}
\end{center}
\end{frame}

\begin{frame}
\frametitle{\textcolor{brique}{ K-NN in practice}}
The overfitting problem: 
\begin{itemize}
\item[] 
   \only<1> {\includegraphics[width = 0.8\textwidth]{k-NN-over.png} \\ }
   \only<2> {\includegraphics[width = 0.8\textwidth]{k-NN-under.png} \\ }
   \only<3> {\includegraphics[width = 0.8\textwidth]{k-NN-well.png} \\ }
   \only<4> {\includegraphics[width = 0.8\textwidth]{k-NN-over.png} \\ }  
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{\textcolor{brique}{ K-NN in practice}}
The overfitting problem:
\begin{itemize}[<+->]
\item[] \includegraphics[width = 0.5\textwidth]{k-NN-over.png} 
\item[] Overfitting has many consequences
\item The estimated curve follows the data too closely
\item The estimated curve follows the \textbf{errors} too closely
\item The estimated function will not provide good estimates on \textbf{new observations}
\end{itemize}
\end{frame}




\section{Machine learning}


\begin{frame}
\frametitle{\textcolor{brique}{ What learning means?}}
The goal is to estimate $f(\cdot)$
\begin{itemize}[<+->]
\item Many statistical learning methods are relevant and useful to estimate $f(\cdot)$
\item $f(\cdot)$ can take continuous (regression) or discrete values (classification)
\item Choosing the best method is difficult
\item If predicting is the goal, one may focus on prediction accuracy \textbf{on a test set}
\item But computing the prediction error is difficult
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{\textcolor{brique}{ What learning means?}}
The classical approach 
\begin{itemize}[<+->]
\item So far, we have estimated $f(\cdot)$ on the whole data set
\item[] \includegraphics[width = 0.8\textwidth]{ML-Sets1.png}
\item[] We have estimated $f(\cdot)$ by $\widehat f(\cdot)$  and minimized the Mean Squared Error (MSE)
\item[] $$ MSE =  \frac{1}{n} \; \sum_ {i=1}^n \bigl( y_i - \widehat f(x_i) \bigr)^2 $$ 
\item The data serve both for estimating $\widehat f(\cdot)$ and computing the error
\item This is prone to overfitting
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{\textcolor{brique}{ What learning means?}}
A different approach: \textit{resampling}
\begin{itemize}[<+->]
\item Our goal is  evaluate the prediction accuracy of $\widehat f(\cdot)$ on a new, \textbf{unseen}, data set 
\item Since we may not have \textbf{unseen} data, we will construct one
\item[] \includegraphics[width = 0.8\textwidth]{ML-Sets4.png}
\item And the true value of $y_i$ will be available to compute MSE of the prediction
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{\textcolor{brique}{Why different sets? }}
Predicting  using predictions capability
\begin{itemize}[<+->]
\item When estimating $f(\cdot)$ on the whole data set, over-fitting may occur
\item The validation set provides a good way to evaluate the prediction capabilities of a model and the prediction error on a new data set
\item[] \includegraphics[width = 0.8\textwidth]{ML-Sets4.png}
\item Prediction accuracy (using $\widehat f(\cdot)$) is then evaluated on the validation set \textbf{only}
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{\textcolor{brique}{Constructing (Test-validation) sets}}
In practice, the validation set is not a block
\begin{itemize}[<+->]
\item[] \includegraphics[width = 0.8\textwidth]{ML-Sets4.png}
\item The validation set is constructed from a randomly drowned observations.
\item[] \includegraphics[width = 0.8\textwidth]{ML-Sets5.png}
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{\textcolor{brique}{\textit{Many} different sets!  }}
Using resampling methods to  estimate the error on the prediction
\begin{itemize}[<+->]
\item Cross validation is used to select $m$-(training-validation) sets from the original data set (here again randomly)
\only<1> {\includegraphics[width = 0.8\textwidth]{CV-Sets1.png}}
\only<2-3> {\includegraphics[width = 0.8\textwidth]{CV-Sets2.png}}
% \item we can then produce $k$ different situations 
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{\textcolor{brique}{\textit{Many} different sets!  }}
\textit{m-fold} Cross-Validation estimates the average prediction error on $m$ different(training-validation) sets
\begin{itemize}[<+->]
\item For each training-validation) set $i$, one can compute the $MSE_i$ since the true $y_i$ is known on the validation set! 
\item Cross Validation error is then: 
 $$ CV_{(m)}  =  \frac{1}{m} \; \sum_ {i=1}^m   MSE_i$$
 \item $CV_{(m)}$ is a good estimate of the prediction error of the model 
 \item  $CV_{(m)} $  can serve to select and compare models (example: select  $k$ in k-NN regression)
 \item Inpractice $m \in {5, \cdots, 10}$ shows good performances
\end{itemize}
\end{frame}





\end{document}

\begin{frame} % Cover slide
\frametitle{ }
\pause
 \begin{itemize}[<+->]
  \item[]
  \item
 \end{itemize}
\end{frame}




%%%%%%%%%%%%%%% Last Slide %%%%%%%%%%%%%%%%

\begin{frame}[allowframebreaks]%in case more than 1 slide needed
\frametitle{References}
    {\footnotesize
    %\bibliographystyle{authordate1}
    \bibliographystyle{apalike}
    \bibliography{../../../Visualisation/Visu}
    }
\end{frame}
\end{document}

%\bibliographystyle{authordate1}
%\bibliography{c:/Chris/Visualisation/Visu}
%\end{frame}
